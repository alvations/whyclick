{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random \n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import click\n",
    "\n",
    "from whyclick.chrome import open_chrome, remove_popups\n",
    "from whyclick import whyq\n",
    "\n",
    "import torch\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromedriver is already installed.\n"
     ]
    }
   ],
   "source": [
    "query = {'username': \"*****\", 'password': \"*****\"}\n",
    "\n",
    "driver = whyq.login(query['username'], query['password'], headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_json = whyq.download_previous_orders(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_items = [o['Item Name'] for o in order_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tonkatsu Set (Chicken Cutlet) (Japanese Food & Salad - MSI)',\n",
       " 'Balinese Gyudon Egg Bowl (Rayyan – Amoy)',\n",
       " 'Hor Fun (Healthy Vegetarian-Amoy)',\n",
       " 'Pulled Pork Quesadilla (James Quesadilla & Brunch -Amoy)',\n",
       " 'Moussaka (Avail Thurs/Fri)(Fill-a-pita) (Fill-a-pita-Standalone)',\n",
       " \"Pasta Aglio-Olio Mushroom (M)  (Chef'B Western - Amoy)\",\n",
       " 'Fish & Chips (Chef B Western - Amoy)',\n",
       " 'Homemade Hamburger (Beef)(Zipp Burger & Pasta-Amoy)',\n",
       " 'Char Siew Biryani Bento  (Chop Chop Biryani & Meats-Amoy)',\n",
       " 'Crispy Chicken Chop Rice (Chikedap - Amoy)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_items[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text):\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
    "    ff = model(input_ids)\n",
    "    output = ff[0].squeeze().squeeze()[0]\n",
    "    return output.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:06<00:00, 15.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converts sentences to arrays of floats.\n",
    "vectorized_sents = [vectorize(s) for s in tqdm(ordered_items)]\n",
    "vectorized_sents = torch.tensor(np.array(vectorized_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://whyq.sg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartly_order_one_day(driver, element_day, simple_max=False, halal=False, healthy=False, vegetarian=False):\n",
    "    time.sleep(1)\n",
    "    loop_count = 0 # Sanity break.\n",
    "    global tempered_vectorized_sents\n",
    "    while True:\n",
    "        try:\n",
    "            # Apply dietary filter\n",
    "            whyq.apply_dietary_filters(driver, halal, healthy, vegetarian)\n",
    "            # Find meals.\n",
    "            meals = [b for b in element_day.find_elements_by_xpath('//button')\n",
    "                     if b and b.text == \"ADD\"]\n",
    "\n",
    "            meals_str = [h6.text for h6 in element_day.find_elements_by_xpath('//h6')][:len(meals)]\n",
    "            meals_vec = torch.tensor(np.array([vectorize(m) for m in meals_str]))\n",
    "            \n",
    "            # For every meal choice, I find what's most similar, by scores with temperature. \n",
    "            sim_scores = torch.tensor(np.dot(meals_vec, tempered_vectorized_sents.T))\n",
    "            if simple_max:\n",
    "                \"\"\" Old neural top-1 choice.\n",
    "                top_m, top_m_score = -1, -1\n",
    "                for i, m in enumerate(meals_vec):\n",
    "                    for s in vectorized_sents:\n",
    "                        if np.dot(m, s.T) > top_m_score:\n",
    "                            top_m = i\n",
    "                \"\"\"\n",
    "                top_m = int(torch.max(torch.max(sim_scores, dim=1).values, dim=0).indices)\n",
    "            else:\n",
    "                # For every meal choice, pick from a multinomial distribution.\n",
    "                top_m = int(torch.multinomial(torch.max(sim_scores, dim=1).values, 1).view(-1))\n",
    "            \n",
    "            meals[top_m].click()\n",
    "\n",
    "            # Randomly choose one.\n",
    "            ##random.choice(meals).click()\n",
    "\n",
    "            # Check if you've ordered already.\n",
    "            time.sleep(0.3)\n",
    "            msg = element_day.find_element_by_xpath('//div[@id=\"notify_msg\"]')\n",
    "            break\n",
    "        except IndexError: # No meals from dietary restriction.\n",
    "            # Repeat the loop so that the filters are undone.\n",
    "            pass\n",
    "        if loop_count > 3: # Sanity break.\n",
    "            break # If everything fails, go to next day.\n",
    "        loop_count += 1\n",
    "    return driver, element_day, msg.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.7\n",
    "tempered_vectorized_sents = vectorized_sents.div(temperature).exp().cpu()\n",
    "#tempered_vectorized_sents = vectorized_sents\n",
    "\n",
    "days = driver.find_elements_by_xpath(\"//div[@class='owl-item active']\")\n",
    "\n",
    "for element_day in days:\n",
    "    element_day.click()\n",
    "    driver, element_day, msg = smartly_order_one_day(\n",
    "        driver, element_day, #simple_max=True\n",
    "    )\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_link_text(\"PLACE ORDER\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
